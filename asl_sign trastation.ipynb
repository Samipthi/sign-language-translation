{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0\n",
      "Collecting data for class 1\n",
      "Collecting data for class 2\n",
      "Collecting data for class 3\n",
      "Collecting data for class 4\n",
      "Collecting data for class 5\n",
      "Collecting data for class 6\n",
      "Collecting data for class 7\n",
      "Collecting data for class 8\n",
      "Collecting data for class 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATA_DIR = './data1'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "number_of_classes = 10\n",
    "dataset_size = 100\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for j in range(number_of_classes):\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
    "\n",
    "    print('Collecting data for class {}'.format(j))\n",
    "\n",
    "    done = False\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "    counter = 0\n",
    "    while counter < dataset_size:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.putText(frame, 'Ready? Press \"Esc\" to exit!', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(25) == 27:  # ASCII value of 'Esc' key is 27\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data1'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "\n",
    "            \n",
    "\n",
    "f = open('data1.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n",
      "Cross-Validation Scores: [0.98994975 0.9798995  1.         1.         1.        ]\n",
      "Mean CV Accuracy: 99.40%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dict = pickle.load(open('./data1.pickle', 'rb'))\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model_digit = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "\n",
    "model_digit.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model_digit.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_predict)\n",
    "print('Test Accuracy: {:.2f}%'.format(test_accuracy * 100))\n",
    "\n",
    "# Perform cross-validation to assess generalization performance\n",
    "cv_scores = cross_val_score(model_digit, data, labels, cv=5)\n",
    "print('Cross-Validation Scores: {}'.format(cv_scores))\n",
    "print('Mean CV Accuracy: {:.2f}%'.format(np.mean(cv_scores) * 100))\n",
    "\n",
    "f = open('model_trial.p', 'wb')\n",
    "pickle.dump({'model': model_digit}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1 Score:  1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    " \n",
    "# Precision\n",
    "precision = precision_score(y_test, y_predict, average='weighted')\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_predict, average='weighted')\n",
    "print(\"Recall: \", recall) \n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.heatmap(cm, annot=True)\n",
    "print(\"Accuracy:\", accuracy_score(y_test,y_predict)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Load the hand gesture recognition model\n",
    "model_digit_dict = pickle.load(open('./model_trial.p', 'rb'))\n",
    "model_digit = model_digit_dict['model']\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "root.geometry(\"1100x1000\")\n",
    "\n",
    "# Create a canvas to display the webcam feed\n",
    "canvas = tk.Canvas(root, width=600, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "predicted_label = tk.Label(root, text=\"Predicted Character: \", font=(\"Helvetica\", 16))\n",
    "predicted_label.pack()\n",
    "\n",
    "save_text = tk.Label(root, text=\"Word: \", font=(\"Helvetica\", 16))\n",
    "save_text.pack()\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Define labels for hand gestures\n",
    "labels_dict_digit = {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '0'}\n",
    "\n",
    "# Function to process webcam frames and perform hand gesture recognition\n",
    "\n",
    "def process_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        H, W, _ = frame.shape\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(frame_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Use only the first detected hand (index 0)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            data_aux = []\n",
    "            x_ = []\n",
    "            y_ = []\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append(x - min(x_))\n",
    "                data_aux.append(y - min(y_))\n",
    "\n",
    "            x1 = int(min(x_) * W) - 10\n",
    "            y1 = int(min(y_) * H) - 10\n",
    "\n",
    "            x2 = int(max(x_) * W) - 10\n",
    "            y2 = int(max(y_) * H) - 10\n",
    "\n",
    "            prediction = model_digit.predict([np.asarray(data_aux)])\n",
    "            predicted_character = labels_dict_digit[int(prediction[0])]\n",
    "            predicted_label.config(text=\"Predicted Character: \" + predicted_character)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "        # Convert the frame to a format that can be displayed by Tkinter\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img = ImageTk.PhotoImage(image=img)\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "        canvas.img = img\n",
    "\n",
    "    # Call this function again after a delay\n",
    "    root.after(30, process_frame)\n",
    "word = \"\" \n",
    "def save_letter():\n",
    "    global word\n",
    "    predicted_character = predicted_label.cget(\"text\").split()[-1]  # Get the predicted character from the label\n",
    "    word+=predicted_character\n",
    "    if len(word) > 0:  # Save the letter if it's a single character \n",
    "        save_text.config(text=\"Word: \" + word)\n",
    "       \n",
    "def save_word():\n",
    "    global word\n",
    "    if len(word) > 0:\n",
    "        # Save the entire word to the file and reset the word variable\n",
    "        with open(\"letters.txt\", \"a\") as f:\n",
    "            f.write(word + \"\\n\")  # Write the word to the file\n",
    "        \n",
    "        # Reset the word variable and update the save_text label\n",
    "        word = \"\"\n",
    "        save_text.config(text=\"Word: \" + word)\n",
    "\n",
    "def clear():\n",
    "    save_text.config(text=\"Word: \" )\n",
    "    global word\n",
    "    word=\"\"\n",
    "    \n",
    "# Start capturing from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Call the function to start processing frames\n",
    "process_frame()\n",
    "\n",
    "# Button to save the predicted character\n",
    "save_button = tk.Button(root, text=\"Save Letter\", command=save_letter,bd=2, padx=10, pady=5)\n",
    "save_button.pack()\n",
    "\n",
    "clear_button = tk.Button(root,text=\"clear\",command=clear,bd=2, padx=10, pady=5)\n",
    "clear_button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the video capture and close all windows when done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Load the hand gesture recognition model\n",
    "model_digit_dict = pickle.load(open('./model_trial.p', 'rb'))\n",
    "model_digit = model_digit_dict['model']\n",
    "\n",
    "model_hand_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model_hand = model_hand_dict['model']  \n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Hand Gesture Recognition\")\n",
    "root.geometry(\"1100x1000\")\n",
    "\n",
    "# Create a canvas to display the webcam feed\n",
    "canvas = tk.Canvas(root, width=600, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "predicted_label = tk.Label(root, text=\"Predicted Character: \", font=(\"Helvetica\", 16))\n",
    "predicted_label.pack()\n",
    "\n",
    "mode_label = tk.Label(root, text=\"Current Mode: Hand Gesture Recognition\", font=(\"Helvetica\", 14))\n",
    "mode_label.pack()\n",
    "\n",
    "save_text = tk.Label(root, text=\"Word: \", font=(\"Helvetica\", 16))\n",
    "save_text.pack()\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Define labels for hand gestures\n",
    "labels_dict_digit = {0: '1', 1: '2', 2: '3', 3: '4', 4: '5', 5: '6', 6: '7', 7: '8', 8: '9', 9: '0'}\n",
    "\n",
    "labels_dict_hand = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M',\n",
    "               12: 'N', 13: 'O', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'U', 19: 'V', 20: 'W', 21: 'X', 22: 'Y',\n",
    "               23: 'THUMBS_UP', 24: 'HEART', 25: 'SUPER'}\n",
    "\n",
    "\n",
    "def process_hand_frame(frame):\n",
    "        H, W, _ = frame.shape\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(frame_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Use only the first detected hand (index 0)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            data_aux = []\n",
    "            x_ = []\n",
    "            y_ = []\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append(x - min(x_))\n",
    "                data_aux.append(y - min(y_))\n",
    "\n",
    "            x1 = int(min(x_) * W) - 10\n",
    "            y1 = int(min(y_) * H) - 10\n",
    "\n",
    "            x2 = int(max(x_) * W) - 10\n",
    "            y2 = int(max(y_) * H) - 10\n",
    "\n",
    "            prediction = model_hand.predict([np.asarray(data_aux)])\n",
    "            predicted_character = labels_dict_hand[int(prediction[0])]\n",
    "            predicted_label.config(text=\"Predicted Character: \" + predicted_character)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                        cv2.LINE_AA)\n",
    "# Function to process webcam frames and perform hand gesture recognition\n",
    "\n",
    "def process_digit_frame(frame):\n",
    "        H, W, _ = frame.shape\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(frame_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Use only the first detected hand (index 0)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            data_aux = []\n",
    "            x_ = []\n",
    "            y_ = []\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append(x - min(x_))\n",
    "                data_aux.append(y - min(y_))\n",
    "\n",
    "            x1 = int(min(x_) * W) - 10\n",
    "            y1 = int(min(y_) * H) - 10\n",
    "\n",
    "            x2 = int(max(x_) * W) - 10\n",
    "            y2 = int(max(y_) * H) - 10\n",
    "\n",
    "            prediction = model_digit.predict([np.asarray(data_aux)])\n",
    "            predicted_character = labels_dict_digit[int(prediction[0])]\n",
    "            predicted_label.config(text=\"Predicted Character: \" + predicted_character)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "def process_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if mode == \"hand\":\n",
    "            process_hand_frame(frame)\n",
    "        elif mode == \"digit\":\n",
    "            process_digit_frame(frame)\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img = ImageTk.PhotoImage(image=img)\n",
    "        canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "        canvas.img = img\n",
    "\n",
    "    # Call this function again after a delay\n",
    "    root.after(30, process_frame)\n",
    "\n",
    "def switch_to_hand_mode():\n",
    "    global mode\n",
    "    mode = \"hand\"\n",
    "    mode_label.config(text=\"Current Mode: Hand Gesture Recognition\")\n",
    "\n",
    "def switch_to_digit_mode():\n",
    "    global mode\n",
    "    mode = \"digit\"\n",
    "    mode_label.config(text=\"Current Mode: Digit Recognition\")\n",
    "\n",
    "mode = \"hand\"  # Start with hand gesture recognition mode\n",
    "\n",
    "hand_mode_button = tk.Button(root, text=\"Hand Gesture Recognition\", command=switch_to_hand_mode, bd=2, padx=10, pady=5)\n",
    "hand_mode_button.pack(side=tk.LEFT, padx=20, pady=10)\n",
    "\n",
    "digit_mode_button = tk.Button(root, text=\"Digit Recognition\", command=switch_to_digit_mode, bd=2, padx=10, pady=5)\n",
    "digit_mode_button.pack(side=tk.LEFT, padx=20, pady=10)\n",
    "\n",
    "word = \"\" \n",
    "def save_letter():\n",
    "    global word\n",
    "    predicted_character = predicted_label.cget(\"text\").split()[-1]  # Get the predicted character from the label\n",
    "    word+=predicted_character\n",
    "    if len(word) > 0:  # Save the letter if it's a single character \n",
    "        save_text.config(text=\"Word: \" + word)\n",
    "       \n",
    "def save_word():\n",
    "    global word\n",
    "    if len(word) > 0:\n",
    "        # Save the entire word to the file and reset the word variable\n",
    "        with open(\"letters.txt\", \"a\") as f:\n",
    "            f.write(word + \"\\n\")  # Write the word to the file\n",
    "        \n",
    "        # Reset the word variable and update the save_text label\n",
    "        word = \"\"\n",
    "        save_text.config(text=\"Word: \" + word)\n",
    "\n",
    "def clear():\n",
    "    save_text.config(text=\"Word: \" )\n",
    "    global word\n",
    "    word=\"\"\n",
    "    \n",
    "# Start capturing from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Call the function to start processing frames\n",
    "process_frame()\n",
    "\n",
    "# Button to save the predicted character\n",
    "save_button = tk.Button(root, text=\"Save Letter\", command=save_letter,bd=2, padx=10, pady=5)\n",
    "save_button.pack()\n",
    "\n",
    "clear_button = tk.Button(root,text=\"clear\",command=clear,bd=2, padx=10, pady=5)\n",
    "clear_button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the video capture and close all windows when done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'multiple_linear_regression_model_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(multiple_regression_model_new)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m x_new :\n\u001b[1;32m---> 23\u001b[0m    prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmultiple_linear_regression_model_new\u001b[49m ( sample)\n\u001b[0;32m     24\u001b[0m    \u001b[38;5;28mprint\u001b[39m ( \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Input : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39msample\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m , Prediction : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mprediction\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multiple_linear_regression_model_new' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def multiple_regression_model(x,y,learning_rate=0.01,num_interatons=1000):\n",
    "  n, m=x.shape\n",
    "  x=np.hstack((np.ones((n,1)),x))\n",
    "  weights=np.zeros((m+1,1))\n",
    "  for _ in range(num_interatons):\n",
    "    predict=x @ weights\n",
    "    loss=((1/2*n))*np.sum((predict-y)**2)\n",
    "    gradient=(1/n) * x.T @ (predict-y)\n",
    "    weights -= learning_rate*np.mean(gradient,axis=1,keepdims=True)\n",
    "  def predict(x):\n",
    "    x_with_bias=np.hstack((1,x))\n",
    "    return np.dot(x_with_bais, weights).item()\n",
    "    \n",
    "    return predict\n",
    "\n",
    "x_new=np.array([[1,2],[2,3],[3,4],[4,5]])\n",
    "y_new=np.array([4,7,10,13])\n",
    "multiple_regression_model_new= multiple_regression_model(x_new ,y_new,learning_rate=0.01,num_interatons=1000)\n",
    "print(multiple_regression_model_new)\n",
    "\n",
    "for sample in x_new :\n",
    "   prediction = multiple_linear_regression_model_new ( sample)\n",
    "   print ( f\" Input : { sample } , Prediction : { prediction }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : [1 2] , Prediction : 7.703380342345878\n",
      "Input : [2 3] , Prediction : 8.12531112521953\n",
      "Input : [3 4] , Prediction : 8.547241908093184\n",
      "Input : [4 5] , Prediction : 8.969172690966836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def multiple_linear_regression (X , y , learning_rate =0.01 ,\n",
    "num_iterations =1000) :\n",
    "    N , M = X . shape\n",
    "\n",
    "    X = np . hstack (( np . ones (( N , 1) ) , X ) )\n",
    "    weights = np . zeros (( M + 1 , 1) )\n",
    "\n",
    "    for _ in range ( num_iterations ) :\n",
    "        predictions = X @ weights\n",
    "        loss = (1 / (2 * N ) ) * np . sum (( predictions - y ) **2)\n",
    "        gradients = (1 / N ) * X . T @ ( predictions - y )\n",
    "        weights -= learning_rate * np . mean ( gradients , axis=1 , keepdims = True )\n",
    "\n",
    "    def predict ( x ) :\n",
    "        x_with_bias = np . hstack ((1 , x ) )\n",
    "        return np . dot ( x_with_bias , weights ) . item ()\n",
    "\n",
    "    return predict\n",
    "\n",
    " # Example usage :\n",
    "\n",
    "X_new = np . array ([[1 , 2] , [2 , 3] , [3 , 4] , [4 , 5]])\n",
    "y_new = np . array ([4 , 7 , 10 , 13])\n",
    "\n",
    "multiple_linear_regression_model_new =multiple_linear_regression ( X_new , y_new , learning_rate=0.01 , num_iterations =1000)\n",
    "\n",
    "for sample in X_new :\n",
    "    prediction = multiple_linear_regression_model_new ( sample)\n",
    "    print ( f\"Input : { sample } , Prediction : { prediction }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Updated ␣ theta ␣ values :  [0.0, 0.30000000000000004]\n",
      " Predictions :  [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    " # Sigmoid function\n",
    "def sigmoid ( z ):\n",
    "    return 1 / (1 + math . exp ( - z ))\n",
    "\n",
    " # Hypothesis function\n",
    "def hypothesis ( theta , X ):\n",
    "    return sigmoid ( sum ([ theta [ i ] * X [ i ]\n",
    "    for i in range ( len ( theta ))]))\n",
    "\n",
    " # Cost function\n",
    "def cost_function ( theta , X , y ):\n",
    "    m = len ( y )\n",
    "    total_cost = 0\n",
    "    for i in range ( m ):\n",
    "        h = hypothesis ( theta , X [ i ])\n",
    "        total_cost += ( - y [ i ] *\n",
    "        math . log ( h )) -((1 - y [ i ]) *math . log (1 - h ))\n",
    "    return total_cost / m\n",
    "\n",
    " # Gradient descent\n",
    "def gradient_descent ( theta , X , y , alpha , num_iters ):\n",
    "    m = len ( y )\n",
    "    theta_updated = theta . copy ()\n",
    "    for _ in range ( num_iters ):\n",
    "        gradients = [0] * len ( theta )\n",
    "    for i in range ( len ( theta )):\n",
    "        sum = 0\n",
    "    for j in range ( m ):\n",
    "        h = hypothesis ( theta_updated , X [ j ])\n",
    "        sum += ( h - y [ j ]) * X [ j ][ i ]\n",
    "        gradients [ i ] = sum / m\n",
    "    for i in range ( len ( theta )):\n",
    "        theta_updated [ i ] = theta_updated [ i ]- alpha* gradients [ i ]\n",
    "    return theta_updated\n",
    "\n",
    "\n",
    " # Predict function\n",
    "def predict ( theta , X ):\n",
    "    predictions = []\n",
    "    for x in X :\n",
    "        h = hypothesis ( theta , x )\n",
    "        prediction = 1 if h >= 0.5 else 0\n",
    "        predictions . append ( prediction )\n",
    "    return predictions\n",
    "\n",
    " # Example usage\n",
    "X = [[1 , 35] , [1 , 25] , [1 , 10] , [1 , 15] , [1 , 45]]\n",
    "y = [1 , 0 , 0 , 0 , 1]\n",
    "theta = [0 , 0]\n",
    "alpha = 0.1\n",
    "num_iters = 10000\n",
    "\n",
    "updated_theta = gradient_descent ( theta , X , y , alpha , num_iters )\n",
    "print ( \" Updated ␣ theta ␣ values : \" , updated_theta )\n",
    "predictions = predict ( updated_theta , X )\n",
    "print ( \" Predictions : \" , predictions )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
